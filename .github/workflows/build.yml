name: Build

on:
  workflow_dispatch:
  push:
    branches:
      - master
    paths: ['.github/workflows/build.yml', '.github/workflows/build-linux-cross.yml', '**/CMakeLists.txt', '**/.cmake', '**/*.h', '**/*.hpp', '**/*.c', '**/*.cpp', '**/*.cu', '**/*.cuh', '**/*.swift', '**/*.m', '**/*.metal', '**/*.comp']

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref && github.ref || github.run_id }}
  cancel-in-progress: true

env:
  GGML_NLOOP: 3
  GGML_N_THREADS: 1
  LLAMA_LOG_COLORS: 1
  LLAMA_LOG_PREFIX: 1
  LLAMA_LOG_TIMESTAMPS: 1

jobs:
  ubuntu-latest-cmake-cuda:
    runs-on: ubuntu-latest
    container: nvidia/cuda:12.6.3-devel-ubuntu24.04

    steps:
        - name: Clone
          id: checkout
          uses: actions/checkout@v4

        - name: Install dependencies
          env:
            DEBIAN_FRONTEND: noninteractive
          run: |
              apt update
              apt install -y cmake build-essential ninja-build libgomp1 git libcurl4-openssl-dev zip

        - name: ccache
          uses: hendrikmuhs/ccache-action@v1.2.18
          with:
            key: ubuntu-latest-cmake-cuda
            evict-old-files: 1d

        - name: Build with CMake
          run: |
            cmake -S . -B build -G Ninja \
              -DCMAKE_BUILD_TYPE=Release -DLLAMA_BUILD_SERVER=ON -DGGML_CUDA=ON \
              -DCMAKE_CUDA_ARCHITECTURES=89-real \
              -DGGML_CUDA_FA_ALL_QUANTS=ON -DGGML_BLAS=OFF
              -DCMAKE_EXE_LINKER_FLAGS=-Wl,--allow-shlib-undefined \
              -DLLAMA_FATAL_WARNINGS=ON \
              -DGGML_NATIVE=OFF -DGGML_RPC=OFF
            cmake --build build

  windows-2022-cmake-cuda:
    runs-on: windows-2022

    strategy:
      matrix:
        cuda: ['12.6']

    steps:
      - name: Clone
        id: checkout
        uses: actions/checkout@v4

      - name: Install ccache
        uses: hendrikmuhs/ccache-action@v1.2.18
        with:
          key: windows-cuda-${{ matrix.cuda }}
          variant: ccache
          evict-old-files: 1d

      - name: Install Cuda Toolkit
        uses: ./.github/actions/windows-setup-cuda
        with:
          cuda_version: ${{ matrix.cuda }}

      - name: Install Ninja
        id: install_ninja
        run: |
          choco install ninja

      - name: libCURL
        id: get_libcurl
        uses: ./.github/actions/windows-setup-curl

      - name: Build
        id: cmake_build
        shell: cmd
        env:
          CURL_PATH: ${{ steps.get_libcurl.outputs.curl_path }}
          # -DGGML_CPU_ALL_VARIANTS=ON ^
        run: |
          call "C:\Program Files\Microsoft Visual Studio\2022\Enterprise\VC\Auxiliary\Build\vcvarsall.bat" x64
          cmake -S . -B build -G "Ninja Multi-Config" ^
            -DLLAMA_BUILD_SERVER=ON -DGGML_CUDA=ON ^
            -DCMAKE_CUDA_ARCHITECTURES=89 -DGGML_CUDA_FA_ALL_QUANTS=ON -DGGML_BLAS=OFF ^
            -DGGML_NATIVE=OFF ^
            -DGGML_RPC=OFF
          set /A NINJA_JOBS=%NUMBER_OF_PROCESSORS%-1
          cmake --build build --config Release -j %NINJA_JOBS% -t ggml
          cmake --build build --config Release

